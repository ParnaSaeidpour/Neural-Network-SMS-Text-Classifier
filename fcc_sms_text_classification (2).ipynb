{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nEmK8A5Z_SK"
      },
      "source": [
        "Import **Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RZOuS9LWQvv",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  !pip install tf-nightly\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "!pip install tensorflow-datasets\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Import Tokenizer and pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "!pip install nltk\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.corpus import stopwords\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q37Z-9ln8oNI",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "nltk.download('stopwords') # download stopwords\n",
        "nltk.download('wordnet') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v73w3gmea3pl",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "MAXLIN = 500\n",
        "VOCAB_SIZE = 1000\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er7usWfGqIju"
      },
      "source": [
        "**Useful** Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qk7WLsaQp_Gv",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_txt(txt):\n",
        "    txt = re.sub(r'([^\\s\\w])+', ' ', txt)\n",
        "    txt = \" \".join([lemmatizer.lemmatize(word) for word in txt.split()\n",
        "                    if not word in stopwords_eng])\n",
        "    txt = txt.lower()\n",
        "    return txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GjkwmFtAfeP",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def preprocessing(X):\n",
        "  x = X.apply(lambda x: clean_txt(x))\n",
        "  x = tokenizer.texts_to_sequences(x)\n",
        "  return keras.preprocessing.sequence.pad_sequences(x, MAXLIN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMHwYXHXCar3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_h508FEClxO",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(train_file_path, sep=\"\\t\", header=None, names=['y', 'x'])\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOMKywn4zReN",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv(test_file_path, sep=\"\\t\", header=None, names=['y', 'x'])\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhOMUeYAozbx",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#categorized each of  variables into numbers \n",
        "y_train = train_data['y'].astype('category').cat.codes\n",
        "y_test  = test_data['y'].astype('category').cat.codes\n",
        "y_train[:10]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WAu72dAsWvx",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "x_train = train_data['x'].astype('category').cat.codes\n",
        "x_test  = test_data['x'].astype('category').cat.codes\n",
        "x_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFFBd4dcvcXB",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "stopwords_eng = set(stopwords.words('english'))\n",
        "len(stopwords_eng)\n",
        "\n",
        "x_train = train_data['x'].apply(lambda x: clean_txt(x))\n",
        "x_train[:5]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzDkIsrUdtf7"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FrxhehanIRG"
      },
      "source": [
        "Create the Tokenizer and define an out of vocabulary token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Cbvp8m_nMz2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words = VOCAB_SIZE, oov_token=\"<OOV>\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qasy43iHn6Cp"
      },
      "source": [
        "Tokenize the words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42Lmmrd-n9ZE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts(x_train)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(x_train)\n",
        "sequences[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3Br1-tldwYi",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "Matrix_sequences =pad_sequences(sequences,MAXLIN)\n",
        "Matrix_sequences[:5]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmP1HURe3SQR"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Faa7oR3X3QpT",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE,50),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='relu')\n",
        "                             \n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qBkqZCo5fh-",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "result = model.fit(Matrix_sequences, y_train,\n",
        "              batch_size=128, epochs=10,\n",
        "              validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pjB1PnR_vuJ"
      },
      "source": [
        "**Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9tD9yACG6M9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text):\n",
        "  p = model.predict(preprocessing(pd.Series([pred_text])))[0]\n",
        "\n",
        "  return (p[0], (\"ham\" if p<0.5 else \"spam\"))\n",
        "\n",
        "pred_text = \"how are you doing today?\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxotov85SjsC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won £1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "fcc_sms_text_classification.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
